{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f154c0ad",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"lab07.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7457142f-4485-4f3b-987d-f3b652e64443",
   "metadata": {},
   "source": [
    "<img src=\"./ccsf.png\" alt=\"CCSF Logo\" width=200px style=\"margin:0px -5px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceee9535-9f3a-49c8-898b-761cdd8469c4",
   "metadata": {},
   "source": [
    "# Lab 07 - A/B Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b593d8-1356-4a7e-bf97-94179ada5cc8",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3ff088-f52e-4316-aee2-806fe58930c9",
   "metadata": {},
   "source": [
    "* [Sections 12.0 - 12.3 of the Textbook](https://inferentialthinking.com/chapters/12/Comparing_Two_Samples.html)\n",
    "* [datascience Documentation](https://datascience.readthedocs.io/)\n",
    "* [Python Quick Reference](https://ccsf-math-108.github.io/materials-fa23/resources/quick_reference.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f048aa5f-b10e-44da-8332-2d596f0be436",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f18e2ff-ad74-465f-a110-f1d30164cc6b",
   "metadata": {},
   "source": [
    "## Lab Assignment Reminders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6a0b57-cc70-43d5-87b1-f91f6e0ae8ee",
   "metadata": {},
   "source": [
    "- üö® Make sure to run the code cell at the top of this notebook that starts with `# Initialize Otter` to load the auto-grader.\n",
    "- Your tasks are categorized as auto-graded (üìç) and manually graded (üìçüîé):\n",
    "    - **For all auto-graded tasks:**\n",
    "        - Replace the `...` in the provided code cell with your own code.\n",
    "        - Run the `grader.check` code cell to execute tests on your code.\n",
    "        - There are no hidden auto-grader tests in the lab assignments. This means if you pass the tests, you can assume you've completed the task successfully.\n",
    "    - **For all manually graded tasks:**\n",
    "        - You may need to provide your own response to the provided prompt. Replace the template text \"_Type your answer here, replacing this text._\" with your own words.\n",
    "        - You might need to produce a graphic or another output using code. Replace the `...` in the code cell to generate the image, table, etc.\n",
    "        - In either case, check your response with a classmate, a tutor, or the instructor before moving on.\n",
    "- Throughout this assignment and all future ones, please **do not re-assign variables** throughout the notebook! _For example, if you use `max_temperature` in your answer to one question, do not reassign it later on. Otherwise, you may fail tests that you thought you were passing previously!_\n",
    "- You may [submit](#Submit-Your-Assignment-to-Canvas) this assignment as many times as you want before the deadline. Your instructor will score the last version you submit once the deadline has passed.\n",
    "- **Collaborating on labs is encouraged!** You should rarely remain stuck for more than a few minutes on questions in labs, so ask an instructor or classmate for help. (Explaining things is beneficial, too -- the best way to solidify your knowledge of a subject is to explain it.) However, please don't just share answers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532f0dc2-1b5a-47f4-895a-47af6640ef22",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29339fc-3d05-4eb1-81bb-476a3b8d4696",
   "metadata": {},
   "source": [
    "## Configure the Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21dd9a88-0438-4fcc-af6e-c1aeec8fe5ce",
   "metadata": {},
   "source": [
    "Run the following cell to configure this Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080d131a-3e0a-444e-a2ae-23f2e64d3870",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datascience import *\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fedd577-20ee-4ffb-9ac2-bee805c1ab88",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74f07c5-ee91-4b51-98c7-9153b95b8e69",
   "metadata": {},
   "source": [
    "## A/B Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a246cfb-a8a6-4f99-b3a3-813e4783b621",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135bc1af-cf1d-4148-a3c0-4bb35fdf99b9",
   "metadata": {},
   "source": [
    "A/B testing is a form of hypothesis testing that allows you to make comparisons between two distributions. We may also refer to an A/B test as a permutation test.\n",
    "\n",
    "You'll almost never be explicitly asked to perform an A/B test. Make sure you can identify situations where the test is appropriate and know how to correctly implement each step. Oftentimes, we use an A/B test to determine whether or not two samples came from the same underlying distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f82fd4f-b065-4cb5-8a51-711a981eaa64",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16535bf-414f-4373-a335-96643145120b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Task 01 üìç"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58762ba4-869c-4e8b-87b0-d69bc703fd51",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "The following statements are the steps of an A/B hypothesis test presented in a random order:\n",
    "\n",
    "1. Choose a test statistic (typically the difference in means between two categories)\n",
    "1. Shuffle the labels of the original sample, find your simulated test statistic, and repeat many times\n",
    "1. Find the value of the observed test statistic\n",
    "1. Calculate the p-value based on your observed and simulated test statistics\n",
    "1. Define a null and alternate model\n",
    "1. Use the p-value and p-value cutoff to draw a conclusion about the null hypothesis\n",
    "\n",
    "Assign `ab_test_order` to an array of integers that contains the correct order of an A/B test, where the first item of the array is the first step of an A/B test and the last item of the array is the last step of an A/B test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e2bcc2-d4ba-4bbd-8a8a-cca7739af4f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ab_test_order = ...\n",
    "ab_test_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2733cc0a",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"task_01\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ad7d9c-6660-4e7f-9d38-7c41f562b9da",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8f15ba-105b-443f-bc87-1e7af112de47",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## The Great British Bake Off"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30fb248-7203-4843-b0ec-6c2af55c54a5",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460a5efc-b06f-49f3-8314-7f697d045c3f",
   "metadata": {},
   "source": [
    ">\"The Great British Bake Off (often abbreviated to Bake Off or GBBO) is a British television baking competition, produced by Love Productions, in which a group of amateur bakers compete against each other in a series of rounds, attempting to impress a group of judges with their baking skills\" [Source: Wikipedia](https://en.wikipedia.org/wiki/The_Great_British_Bake_Off)\n",
    "\n",
    "For every week of the competition, the judges assign one contestant the title \"Star Baker\". Ultimately, one winner is crowned every season. Using this information, we would like to investigate how winning Star Baker awards affects the odds of winning a season of the show."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84198732-301e-4f58-848e-d35f922121d4",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757e18ca-9e38-4d17-8343-c89e42fbfcce",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Task 02 üìçüîé"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11d11d3-6e52-4962-8397-2c1c3f6a7d42",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "We want to know whether winning more Star Baker awards causes a change in likelihood of winning the season. Why is it not sufficient to compare star baker rates for winners and losers?\n",
    "\n",
    "_Check your response with someone else before moving on._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55fce762",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7221d18-894c-4f1b-8718-d82cd8ff85c9",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f9a9ce-a148-4459-a2bb-53d28348f219",
   "metadata": {},
   "source": [
    "We are going to run the following hypothesis test to determine the association between winning and number of Star Baker awards. The population we are examining is every contestant from seasons 2 through 11 of GBBO. We are going to use the following null and alternative hypotheses:\n",
    "\n",
    "**Null hypothesis:** The distribution of Star Baker awards between contestants who won their season and contestants who did not win their season is the same.\n",
    "\n",
    "**Alternative hypothesis:** Contestants who win their season of the show will win more Star Baker awards on average.\n",
    "\n",
    "Our alternative hypothesis is related to our suspicion that contestants who win more Star Baker awards are more skilled, so they are more likely to win the season."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dceb86d3-03b7-4b13-af94-9e334303a88b",
   "metadata": {},
   "source": [
    "The `bakers` table below describes the number of star baker awards each contest won and whether or not they won their season (`1` if they won, `0` if they did not win). The data was manually aggregated from Wikipedia for seasons 2-11 of the show. We randomized the order of rows as to not spoil the outcome of the show."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63295f27-c3b3-465d-ae21-3aabf6547e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "bakers = Table.read_table(\"star_bakers.csv\")\n",
    "bakers.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e356046-9792-4b45-b08d-9e24603f6fe6",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29bacfa4-62a4-4d69-ae14-c39ecf64e62f",
   "metadata": {},
   "source": [
    "## Task 03 üìç"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37beb57-15da-4051-8520-d5b4292e5698",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Create a new table called `means` that contains the mean number of star baker awards for bakers who did not win (`won==0`) and bakers that did win (`won==1`). The table should have the column names `won` and `star baker awards mean`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5acb72a8-1b75-491a-89e4-cbbafb94587b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "means = ...\n",
    "means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff7d999",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"task_03\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e930de-6d5a-4635-b5fc-9bdd89a912f5",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6fbcf4f-29ef-46bb-8b9c-03ae4c1a37d4",
   "metadata": {},
   "source": [
    "## Task 04 üìçüîé"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeeed951-623a-4b3d-ade0-2821c8284282",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "Visualize the distribution of Star Baker awards for winners and non-winners as overlaid histograms. Make sure to:\n",
    "\n",
    "* Use the bins we provided.\n",
    "* Use the group argument of `tbl.hist`. In order to produce several overlayed histograms based on unique values in a given column, we can do something like `tbl.hist(..., group=<col_name>, bins=...)`!\n",
    "\n",
    "_We recommend that you check your histogram with someone before moving on._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0899bdd-e412-44ef-8fbb-0d0778e144b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "useful_bins = np.arange(0, 7)\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a96bf71-b484-4d22-b359-a2ccfd27141f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60da5ca-656e-411f-90a8-e450a0710847",
   "metadata": {},
   "source": [
    "## Task 05 üìçüîé"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784b5750-070d-433a-836f-cf5d24e82a70",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "We want to figure out if there is a difference between the distribution of Star Baker awards between winners and non winners. For the test statistic, subtract the mean star baker awards value for those that didn't win from the mean value for those that did win.\n",
    "\n",
    "Which values of this test statistic support the alternative hypothesis?\n",
    "\n",
    "_Before moving on, confirm your answer with someone._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e667cc",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d5a5ad-cd1a-4e03-8c17-cc4311ba0fd2",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973d0dd2-364a-4640-963f-b3e8088eb739",
   "metadata": {},
   "source": [
    "## Task 06 üìç"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2e0be1-b8e1-4dac-a2b5-c2eb7d0589fd",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Set `observed_difference` to the observed test statistic using the `means` table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06de064c-17ed-4f15-a351-6b4da58e2c62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "observed_difference = ...\n",
    "observed_difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3023bd2c",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"task_06\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be55ded-ea4c-4619-a891-dbdfb52febc5",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d738a032-50d7-4ab3-8f4a-e08a07875f30",
   "metadata": {},
   "source": [
    "## Task 07 üìç"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a7bd00-74a2-43e4-9c2d-10dca4f9325c",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Shortly, you will be calculating that difference on a variety of tables similar to `bakers`, but with the mean values shuffled around. Given a table like `bakers`, a label column `label_col` with two labels, `1` and `0`, and a values column `val_col`, write a function `find_test_stat` that calculates the test statistic outlined above.\n",
    "\n",
    "*Hint*: Make sure that you are taking the directionality of our alternative hypothesis into account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebaa7ff-1b49-45e9-8025-70c395e10eba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_test_stat(tbl, label_col, val_col):\n",
    "    ...\n",
    "\n",
    "# Confirm that your function produces the same observed difference\n",
    "find_test_stat(bakers, \"won\", \"star baker awards\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8d08b6",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"task_07\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9807f7ce-9b4d-41ab-85ab-62edbad0bc81",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef03b4d-ade0-4d15-8f92-2c552f6cdec6",
   "metadata": {},
   "source": [
    "When we run a simulation for A/B testing, we resample by **shuffling the labels** of the original sample. If the null hypothesis is true and the star baker award distributions are the same, we expect that the difference in mean star baker awards to not change when `\"won\"` labels are changed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f56b1e-8ddf-4c12-a9e1-df1e059f63d1",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f89020-e174-4093-939c-2a1be5d87f0d",
   "metadata": {},
   "source": [
    "## Task 08 üìç"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f864a6-e535-4402-8de9-c063f0557ece",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Write a function `simulate_and_test_statistic` to compute one trial of our A/B test. Your function should run a simulation and return a test statistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d700616b-e180-4f94-a5cb-d8bede1a113c",
   "metadata": {
    "for_assignment_type": "solution",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def simulate_and_test_statistic(tbl, labels_col, values_col):\n",
    "    ...\n",
    "\n",
    "simulate_and_test_statistic(bakers, \"won\", \"star baker awards\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8906fa26",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"task_08\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97836377-bcdf-41b6-9898-30d4921a2538",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0fd6d4e-93e5-4f51-8afa-9aad418293f8",
   "metadata": {},
   "source": [
    "## Task 09 üìç"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d25d4cb-4124-40ce-8ca6-ab410885e43c",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Simulate 5000 trials of our A/B test and store the test statistics in an array called `differences`. Once complete, this code cell will take a few minutes to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783c243d-5b08-4da4-8b28-adf6e1857603",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "repetitions = ...\n",
    "differences = ...\n",
    "\n",
    "...                                              \n",
    "\n",
    "differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b232aa",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"task_09\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32fa3346-6597-4010-8f73-98e55b0e7d76",
   "metadata": {},
   "source": [
    "Run the cell below to view a histogram of your simulated test statistics plotted with your observed test statistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142045f7-a9d8-40de-be73-e186a7c8b428",
   "metadata": {},
   "outputs": [],
   "source": [
    "Table().with_column('Difference Between Group Means', differences).hist(bins=20)\n",
    "plt.scatter(observed_difference, 0, color='red', s=30, zorder=2)\n",
    "plt.ylim(-0.1, 1.35);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fddad8ee-ac1e-4b39-927e-89e82ac6a86d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909b5ce8-d4d7-4476-9719-cbd606c313bb",
   "metadata": {},
   "source": [
    "## Task 10 üìç"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fdfa4e-4073-4b28-9657-13170175bfee",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Find the p-value for your test and assign it to `empirical_p`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390a420c-fa34-472a-b9cc-5a4be9b611cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "empirical_p = ...                                             \n",
    "\n",
    "empirical_p "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e8b91e",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"task_10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40724f87-61be-4900-9493-640bc1e5eb1b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e64afb-e826-4456-a149-6668f00658cc",
   "metadata": {},
   "source": [
    "## Task 11 üìçüîé"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82c9299-41f8-4611-9e8a-35d553c49360",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "1. Using a 5% p-value cutoff, draw a conclusion about the null and alternative hypotheses using more the technical language of hypothesis testing.\n",
    "2. Using simple, non-technical language, what does your analysis tell you about the association between star baker awards and winning? \n",
    "3. What can you claim about causation from your statistical analysis? \n",
    "    \n",
    "Confirm your answer with a peer, instructor, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1fff374",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9354e88-20ed-4832-81c9-9f2e7cd2b67e",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6648a099-8e08-4b26-a272-463c471b2eef",
   "metadata": {},
   "source": [
    "## Submit Your Assignment to Canvas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71442469-6249-42a0-9190-616794493e8d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "Follow these steps to submit your lab assignment:\n",
    "\n",
    "1. **Check the Assignment Completion Requirements:** This assignment is scored as Complete or Incomplete. Make sure to check with your instructor about their requirements for a Complete score. \n",
    "2. **Run the Auto-Grader:** Ensure you have executed the code cell containing the command `grader.check_all()` to run all tests for auto-graded tasks marked with üìç. This command will execute all auto-grader tests sequentially.\n",
    "3. **Complete Manually Graded Tasks:** Verify that you have responded to all the manually graded tasks marked with üìçüîé.\n",
    "4. **Save Your Work:** In the notebook's Toolbar, go to `File -> Save Notebook` to save your work and create a checkpoint.\n",
    "5. **Download the Notebook:** In the notebook's Toolbar, go to `File -> Download HTML` to download the HTML version (`.html`) of this notebook.\n",
    "6. **Upload to Canvas:** On the Canvas Assignment page, click \"Start Assignment\" or \"New Attempt\" to upload the downloaded `.html` file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6713688d-bdef-409c-bf6f-b617de8db661",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380b81b6-7a5f-4484-8b4c-8ea8fbcc1818",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "notes"
    },
    "tags": []
   },
   "source": [
    "## Attribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58aa6fc-7274-4f07-939f-d68b9a0c3df1",
   "metadata": {},
   "source": [
    "This content is licensed under the <a href=\"https://creativecommons.org/licenses/by-nc-sa/4.0/\">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License (CC BY-NC-SA 4.0)</a> and derived from the <a href=\"https://www.data8.org/\">Data 8: The Foundations of Data Science</a> offered by the University of California, Berkeley.\n",
    "\n",
    "<img src=\"./by-nc-sa.png\" width=100px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6ccf6c",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "To double-check your work, the cell below will rerun all of the autograder tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce773b96",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check_all()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "otter": {
   "OK_FORMAT": true,
   "assignment_name": "lab07_fa24",
   "tests": {
    "task_01": {
     "name": "task_01",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> len(ab_test_order) == 6\nTrue",
         "failure_message": "‚ùå ab_test_order should have 6 elements. Use make_array and provide the numbers 1-6 in some meaningful order.",
         "hidden": false,
         "locked": false,
         "points": 1,
         "success_message": "‚úÖ ab_test_order has 6 elements."
        },
        {
         "code": ">>> np.allclose(np.array(ab_test_order)[:3] % 2 == 1, True)\nTrue",
         "failure_message": "‚ùå All of the first 3 values in ab_test_order don't seem possible. They should all be odd numbers.",
         "hidden": false,
         "locked": false,
         "points": 1,
         "success_message": "‚úÖ All of the first 3 values in ab_test_order seem possible."
        },
        {
         "code": ">>> np.allclose(np.array(ab_test_order)[3:] % 2 == 0, True)\nTrue",
         "failure_message": "‚ùå All of the last 3 values in ab_test_order don't seem possible. They should all be even numbers.",
         "hidden": false,
         "locked": false,
         "points": 1,
         "success_message": "‚úÖ All of the last 3 values in ab_test_order seem possible."
        },
        {
         "code": ">>> import hashlib\n>>> \n>>> def get_hash(num):\n...     \"\"\"Helper function for assessing correctness.\"\"\"\n...     return hashlib.md5(str(num).encode()).hexdigest()\n>>> get_hash(np.array(ab_test_order).astype(int))\n'a7196ed0f271c873d9750cb92422d911'",
         "failure_message": "‚ùå ab_test_order does not seem correct.",
         "hidden": false,
         "locked": false,
         "points": 1,
         "success_message": "‚úÖ ab_test_order seems correct."
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "task_03": {
     "name": "task_03",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> means.num_rows == 2\nTrue",
         "failure_message": "‚ùå Your table should have 2 rows.",
         "hidden": false,
         "locked": false,
         "points": 1,
         "success_message": "‚úÖ Your table has 2 rows."
        },
        {
         "code": ">>> {'won', 'star baker awards mean'} == set(means.labels)\nTrue",
         "failure_message": "‚ùå Your labels should be 'won' and 'star baker awards mean'.",
         "hidden": false,
         "locked": false,
         "points": 1,
         "success_message": "‚úÖ Your labels seem correct."
        },
        {
         "code": ">>> np.round(min(means.column('star baker awards mean')), 2) == 0.65 and np.round(max(means.column('star baker awards mean')), 2) == 1.5\nTrue",
         "failure_message": "‚ùå Your mean values don't seem correct.",
         "hidden": false,
         "locked": false,
         "points": 1,
         "success_message": "‚úÖ Your mean values seem correct."
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "task_06": {
     "name": "task_06",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> isinstance(observed_difference, float)\nTrue",
         "failure_message": "‚ùå Your observed_difference value should be a float.",
         "hidden": false,
         "locked": false,
         "points": 1,
         "success_message": "‚úÖ Your observed_difference value is a float."
        },
        {
         "code": ">>> float(round(observed_difference, 3)) == 0.848\nTrue",
         "failure_message": "‚ùå Your observed_difference value does't seem correct. Double check that you are subtracing the means for the winners and losers. Also, double check the order of your subtraction.",
         "hidden": false,
         "locked": false,
         "points": 1,
         "success_message": "‚úÖ Your observed_difference value seems correct."
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "task_07": {
     "name": "task_07",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> np.isclose(round(find_test_stat(bakers, 'won', 'star baker awards'), 3) - 0.848, 0)\nTrue",
         "failure_message": "‚ùå Your function should produce the same observed value as in the previous task.",
         "hidden": false,
         "locked": false,
         "points": 1,
         "success_message": "‚úÖ It seems like your function correctly produces the same observed value as in the previous task."
        },
        {
         "code": ">>> shifted_indices = np.roll(np.arange(bakers.num_rows), 2)\n>>> shifted_won_vals = bakers.take(shifted_indices).column('won')\n>>> test_tbl = bakers.select('star baker awards').with_column('Shuffled Label', shifted_won_vals)\n>>> np.isclose(round(find_test_stat(test_tbl, 'Shuffled Label', 'star baker awards'), 3) - -0.132, 0)\nTrue",
         "failure_message": "‚ùå Your function should use the arguments tbl, label_col, val_col to do the calculation.",
         "hidden": false,
         "locked": false,
         "points": 1,
         "success_message": "‚úÖ It seems like your function is using the arguments tbl, label_col, val_col to do the calculation."
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "task_08": {
     "name": "task_08",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> test_stat = round(simulate_and_test_statistic(bakers, 'won', 'star baker awards'), 3)\n>>> -2 < test_stat < 2\nTrue",
         "failure_message": "‚ùå Your test_stat value should be between -2 and 2. Make sure you are using find_test_stat.",
         "hidden": false,
         "locked": false,
         "points": 1,
         "success_message": "‚úÖ Your test_stat value is between -2 and 2."
        },
        {
         "code": ">>> np.random.seed(1)\n>>> test_stat2 = simulate_and_test_statistic(bakers, 'won', 'star baker awards')\n>>> np.round(test_stat2, 3) == -0.023 or np.round(test_stat2, 3) == -0.132\nTrue",
         "failure_message": "‚ùå simulate_and_test_statistic doesn't seem to work as intended. Make sure you are using the sample method with the arguement with_replacement=False to suffle the labels. ",
         "hidden": false,
         "locked": false,
         "points": 1,
         "success_message": "‚úÖ simulate_and_test_statistic seems to work for the table we checked."
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "task_09": {
     "name": "task_09",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> len(differences)\n5000",
         "failure_message": "‚ùå differences should have 5000 items.",
         "hidden": false,
         "locked": false,
         "points": 1,
         "success_message": "‚úÖ differences has 5000 items."
        },
        {
         "code": ">>> abs(np.average(differences)) < 0.05\nTrue",
         "failure_message": "‚ùå On average, your test statistic should be close to 0.",
         "hidden": false,
         "locked": false,
         "points": 1,
         "success_message": "‚úÖ On average, your test statistic should is close to 0"
        },
        {
         "code": ">>> all(differences == differences.item(0)) == False\nTrue",
         "failure_message": "‚ùå Make sure all of the test statistics are different",
         "hidden": false,
         "locked": false,
         "points": 1,
         "success_message": "‚úÖ All of the test statistics are different"
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "task_10": {
     "name": "task_10",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> 0 <= empirical_p < 0.05\nTrue",
         "failure_message": "‚ùå Your p-value should be less than 5%. (It is rare, but there is a small chance you did everything correctly and you just ended up with a p-value that is 5% or larger. Re-run the code in Task 08 and Task 09 to double check.)",
         "hidden": false,
         "locked": false,
         "points": 1,
         "success_message": "‚úÖ Your p-value should be less than 5%."
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
