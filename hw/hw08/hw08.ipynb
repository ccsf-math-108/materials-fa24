{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6eda1f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"hw08.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826b39eb-51f4-4646-ae50-d1280a2706f9",
   "metadata": {},
   "source": [
    "<img src=\"./ccsf.png\" alt=\"CCSF Logo\" width=200px style=\"margin:0px -5px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a853bd-5fbd-45ee-ad8d-29453bc0158b",
   "metadata": {},
   "source": [
    "# Homework 8: A/B Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34e94c4-52fb-403a-9942-f29808c661b6",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "* [Comparing Two Samples](https://inferentialthinking.com/chapters/12/Comparing_Two_Samples.html)\n",
    "* [`datascience` Documentation](https://datascience.readthedocs.io/)\n",
    "* [Python Quick Reference](https://ccsf-math-108.github.io/materials-fa23/resources/quick_reference.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b19623-79aa-4e1a-ac77-74b41bbf8077",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c55b89-0b62-45cc-ab6d-6463a6af4565",
   "metadata": {},
   "source": [
    "## Assignment Reminders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662eb748-effa-4743-896c-4a76edb9f5be",
   "metadata": {},
   "source": [
    "- üö® Make sure to run the code cell at the top of this notebook that starts with `# Initialize Otter` to load the auto-grader.\n",
    "- Your Tasks are categorized as auto-graded (üìç) and manually graded (üìçüîé).\n",
    "    - For all the auto-graded tasks:\n",
    "        - Replace the `...` in the provided code cell with your own code.\n",
    "        - Run the `grader.check` code cell to run some tests on your code.\n",
    "        - Keep in mind that for homework and project assignments, sometimes there are hidden tests that you will not be able to see the results of that we use for scoring the correctness of your response. **Passing the auto-grader does not guarantee that your answer is correct.**\n",
    "    - For all the manually graded tasks:\n",
    "        - You might need to provide your own response to the provided prompt. Do so by replacing the template text \"_Type your answer here, replacing this text._\" with your own words.\n",
    "        - You might need to produce a graphic or something else using code. Do so by replacing the `...` in the code cell to generate the image, table, etc.\n",
    "        - In either case, review the rubric on the associated <a href=\"https://ccsf.instructure.com\" target=\"_blank\">Canvas</a> Assignment page to understand the scoring criteria.\n",
    "- Throughout this assignment and all future ones, please be sure to not re-assign variables throughout the notebook! _For example, if you use `max_temperature` in your answer to one question, do not reassign it later on. Otherwise, you will fail tests that you thought you were passing previously!_\n",
    "- You may [submit](#Submit-Your-Assignment-to-Canvas) this assignment as many times as you want before the deadline. Your instructor will score the last version you submit once the deadline has passed.\n",
    "- We encourage you to discuss this assignment with others but make sure to write and submit your own code. Refer to the syllabus to learn more about how to learn cooperatively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dedf7b4-623f-4064-8d6f-bcf2e96823fc",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687f2f25-7b02-42d7-bcab-a08b193e66ba",
   "metadata": {},
   "source": [
    "## Configure the Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e96723c-ccd5-473e-9801-0a3c50251389",
   "metadata": {},
   "source": [
    "Run the following cell to configure this Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6c5e96-4f58-4d51-88ae-0e4ed73fbe04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datascience import *\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcde4c00-a1bf-49d9-ac9d-909634dc1fd3",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9fb74e-e15e-4b6f-a22e-abcd27d00a10",
   "metadata": {},
   "source": [
    "## Who is Older?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc052646-71dc-4ed4-8b60-bef2c79e7b8b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7c8f1d-0ced-4b8b-97d1-30fa7e6621b9",
   "metadata": {},
   "source": [
    "In an attempt to answer the question 'Who is Older?', data scientists have drawn a simple random sample of size 500 from a large population of adults. Each member of the population happened to identify as either \"male\" or \"female\". Data was collected on several attributes of the sampled people, including age. The table `sampled_ages` contains one row for each person in the sample, with columns containing the individual's gender identity and their age."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7bd494-8333-4458-9106-e61b672ef7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_ages = Table.read_table('age.csv')\n",
    "sampled_ages.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9dc7ab-81c5-43b5-b6ac-b21e50e90936",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e3798e-2226-4904-847a-368ea741ec02",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Task 01 üìç"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0933f85-5dec-4eee-9501-29ff9f0f7edc",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "How many females are there in this sample? Please use the provided skeleton code.\n",
    "\n",
    "*Hint:* Keep in mind that `.group` sorts categories in alphabetical order!\n",
    "\n",
    "_Points:_ 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854495c1-5e1e-4cc5-ab25-30156e02133d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_females = sampled_ages.group(...)...\n",
    "num_females"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efad011",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"task_01\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99bbc723-1172-4388-aa7f-57c8efe39366",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37deab1-2883-4b96-a0f5-02d1f40c2180",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Task 02 üìç"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe2c7ac-4c52-4571-b5dd-75c4889431e4",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Complete the cell below so that `avg_male_vs_female` evaluates to `True` if the sampled males are older than the sampled females on average, and `False` otherwise. Use Python code to achieve this.\n",
    "\n",
    "_Points:_ 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c712d80a-c83c-45d0-8db6-bd0c155698f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "group_mean_tbl = sampled_ages.group(...)\n",
    "group_means = group_mean_tbl...       # array of mean ages\n",
    "avg_male_vs_female = group_means... > group_means...\n",
    "avg_male_vs_female"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fd7e5c",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"task_02\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d62ce2-d26b-48af-89e5-2bd502d0967e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4573db-acaa-4ce4-b316-ffb077a6922d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Task 03 üìç"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32a2c4d-ddbd-406a-8ec7-67e2db135bfd",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "The data scientists want to use the data to test whether males are older than females on average or whether the ages of the two groups have the same distribution. \n",
    "\n",
    "In the code cell below, assign `null_statement_number` and `alternative_statement_number` to the number corresponding to the correct statement from the list below. (There is only one correct answer for each.)\n",
    "\n",
    "1. In the sample, the males and females have the same distribution of ages; the sample averages of the two groups are different due to chance.\n",
    "2. In the population, the males and females have the same distribution of ages; the sample averages of the two groups are different due to chance.\n",
    "3. The age distributions of males and females in the population are different due to chance.\n",
    "4. The males in the sample are older than the females, on average.\n",
    "5. The males in the population are older than the females, on average.\n",
    "6. The average ages of the males and females in the population are different.\n",
    "\n",
    "_Points:_ 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbcf9b01-a113-43ae-a180-a2ec28ff8a6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "null_statement_number = ...\n",
    "alternative_statement_number = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c01e4d",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"task_03\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25abda50-08cb-4d53-a72c-abd9b63dad80",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3fa115-957d-4809-b616-9655b7b5599d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Task 04 üìçüîé"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8a2bb1-f167-46ea-bb74-044cd7140894",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "Why is a permutation test appropriate to use in this situation? In your response, relate this situation to the examples from a class lecture, discussion topic, or the [Chapter 12](https://inferentialthinking.com/chapters/12/1/AB_Testing.html) content.\n",
    "\n",
    "_Points:_ 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd7e3d5",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a0cc5f-9ef4-47bf-8817-006abfa6ff2c",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a9e40d-a99c-4ac7-b774-93737a2217dc",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Task 05 üìç"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb050384-59e4-4aca-8ce2-dca797f56a7d",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "To test their hypotheses, the data scientists have followed our textbook's advice and chosen a test statistic where the following statement is true: Large values of the test statistic favor the alternative hypothesis.\n",
    "\n",
    "The data scientists' test statistic is one of the two options below. Which one is it? Assign the appropriate number to the variable `correct_test_stat`.\n",
    "\n",
    "1. \"male age average - female age average\" in a sample created by randomly shuffling the male/female labels\n",
    "2. \"|male age average - female age average|\" in a sample created by randomly shuffling the male/female labels\n",
    "\n",
    "_Points:_ 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377dc55b-c9f6-4fe9-8464-8e185a44706f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "correct_test_stat = ...\n",
    "correct_test_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2c4a56",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"task_05\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ea9f72-e37f-4546-841e-dfe2296d087e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1febbc9f-26f2-461d-991d-e0c14e5ba6fd",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Task 06 üìç"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e8a740-e562-445d-bb03-031b8183054b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Complete the cell below so that `observed_statistic_ab` evaluates to the observed value of the data scientists' test statistic. Use as many lines of code as you need, and remember that you can use any quantity, table, or array that you created earlier.\n",
    "\n",
    "_Points:_ 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6274161-a8b3-462f-b092-cd2c1bc1038e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "observed_statistic_ab = ...\n",
    "observed_statistic_ab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed79ce22",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"task_06\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed89a80-d1ba-4a98-8a76-f26e1aeeaf54",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc80635a-89ca-4726-bf2e-9818868b1088",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Task 07 üìç"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8867f844-883e-4d3b-ba0f-6f7160c9bf15",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Assign `shuffled_labels` to an array of shuffled male/female labels. The rest of the code puts the array in a table along with the data in `sampled_ages`.\n",
    "\n",
    "*Note:* Check out [12.1](https://inferentialthinking.com/chapters/12/1/AB_Testing.html#predicting-the-statistic-under-the-null-hypothesis) for a refresher on random permutations.\n",
    "\n",
    "_Points:_ 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec77c398-abd9-4aa7-9409-a1c508627048",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "shuffled_labels = ...\n",
    "original_with_shuffled_labels = sampled_ages.with_columns('Shuffled Label', shuffled_labels)\n",
    "original_with_shuffled_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362e6a40",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"task_07\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c739eb6-e44d-444c-bb5f-100e631ea468",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c70596-a8ba-4346-bc47-d07b15a3c7d8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Task 08 üìç"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932cbc4c-59b9-4bcd-ae17-a9a23cc48372",
   "metadata": {
    "deletable": false,
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "The comparison below uses the array `shuffled_labels` from Task 07 and the count `num_females` from Task 01.\n",
    "\n",
    "For this comparison, assign the correct number from one of the following options to the variable `correct_q8`. **Pretend this is a midterm problem and solve it without doing the calculation in a code cell.**\n",
    "\n",
    "`comp = np.count_nonzero(shuffled_labels == 'female') == num_females`\n",
    "\n",
    "1. `comp` is set to `True`.\n",
    "2. `comp` is set to `False`.\n",
    "3. `comp` is set to `True` or `False`, depending on how the shuffle came out.\n",
    "\n",
    "_Points:_ 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23662818-7bc5-4a12-9915-61428f08f103",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "correct_q8 = ...\n",
    "correct_q8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccecc75",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"task_08\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e1cdbf-adb0-4c03-9186-20809c85f8af",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40451f07-1a77-49d5-af71-ff73d0962ed7",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Task 09 üìç"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e48cc6c-b533-4edc-adc0-f282186b881d",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Define a function `simulate_one_statistic` that takes no arguments and returns one simulated value of the test statistic. We've given you a skeleton, but feel free to approach this question in a way that makes sense to you. Use as many lines of code as you need. Refer to the code you have previously written in this problem, as you might be able to re-use some of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b379cc14-aa43-419b-838a-dd8871afa61b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def simulate_one_statistic():\n",
    "    \"Returns one value of our simulated test statistic\"\n",
    "    shuffled_labels = ...\n",
    "    shuffled_tbl = ...\n",
    "    group_means = ...\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea71b44-dd36-4614-8809-3d2a8cfffa7a",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "After you have defined your function, run the following cell a few times to see how the statistic varies.\n",
    "\n",
    "_Points:_ 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7020b25-48a1-46f3-9ab7-ae3e52046e9e",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "simulate_one_statistic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214e3a39",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"task_09\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69de5036-b0a2-456f-9a30-f68fc8fc30bc",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3604e967-d772-4613-9746-6d1f2d18b60f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Task 10 üìç"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f8d9ec-97f9-4d6c-9a13-246ac06fabe2",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Complete the cell to simulate 4,000 values of the statistic. We have included the code that draws the empirical distribution of the statistic and shows the value of `observed_statistic_ab` from Task 06. Feel free to use as many lines of code as you need.\n",
    "\n",
    "*Note:* This cell will take around one minute to run.\n",
    "\n",
    "_Points:_ 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0894a11c-fb40-4917-98c8-0a78e6eeb59b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "repetitions = 4000\n",
    "\n",
    "simulated_statistics_ab = make_array()\n",
    "...\n",
    "    simulated_statistics_ab = ...\n",
    "\n",
    "# Do not change these lines\n",
    "Table().with_columns('Simulated Statistic', simulated_statistics_ab).hist()\n",
    "plt.scatter(observed_statistic_ab, -0.002, color='red', s=70);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6999d58",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"task_10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78506edd-0f65-4f4f-9980-66529fa15626",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770cc379-0348-41fa-ac37-70131a621b92",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Task 11 üìç"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a50d0a-10ba-40f2-8d94-835e9e52a4f5",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Use the simulation to find an empirical approximation to the p-value. Assign `p_val` to the appropriate p-value from this simulation.\n",
    "\n",
    "_Points:_ 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb3a96b-8771-48c4-bb3b-baeab320b94d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "p_val = ...\n",
    "p_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada45a14",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"task_11\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fdfae8-0d29-4675-8cbe-15016e008d94",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7bb01f-8a00-4cf1-ab6f-d1907f52af07",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Task 12 üìçüîé"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11071303-0c11-4d32-9786-74da6a5ae56c",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "What conclusion can we draw from this permutation test? In your response, compare the p-value to an assumed significance level of 5% and indicate whether the data and test results support the null or\" alternative hypothesis.\n",
    "\n",
    "_Points:_ 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955fc9f8",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72cccc8b-9166-4c2d-8486-585867b1bc49",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b38d0e0-6e00-4416-8c90-f6e23cfe3780",
   "metadata": {},
   "source": [
    "## Submit Your Assignment to Canvas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2929def7-a1db-4ca2-a6c1-897b6e875ed2",
   "metadata": {},
   "source": [
    "Follow these steps to submit your homework assignment:\n",
    "\n",
    "1. **Review the Rubric:** View the rubric on the associated Canvas Assignment page to understand the scoring criteria.\n",
    "2. **Run the Auto-Grader:** Ensure you have executed the code cell containing the command `grader.check_all()` to run all tests for auto-graded tasks marked with üìç. This command will execute all auto-grader tests sequentially.\n",
    "3. **Complete Manually Graded Tasks:** Verify that you have responded to all the manually graded tasks marked with üìçüîé.\n",
    "4. **Save Your Work:** In the notebook's Toolbar, go to `File -> Save Notebook` to save your work and create a checkpoint.\n",
    "5. **Download the Notebook:** In the notebook's Toolbar, go to `File -> Download IPYNB` to download the notebook (`.ipynb`) file.\n",
    "6. **Upload to Canvas:** On the Canvas Assignment page, click \"Start Assignment\" or \"New Attempt\" to upload the downloaded `.ipynb` file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd4a2e9-8d99-4b66-bec7-9bb7e8d08d21",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f05d38-25c1-47dc-81d4-ca583352eb64",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "notes"
    },
    "tags": []
   },
   "source": [
    "## Attribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb54e55-2af2-4cf2-a5cf-2352d39ed560",
   "metadata": {},
   "source": [
    "This content is licensed under the <a href=\"https://creativecommons.org/licenses/by-nc-sa/4.0/\">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License (CC BY-NC-SA 4.0)</a> and derived from the <a href=\"https://www.data8.org/\">Data 8: The Foundations of Data Science</a> offered by the University of California, Berkeley.\n",
    "\n",
    "<img src=\"./by-nc-sa.png\" width=100px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e20976",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "To double-check your work, the cell below will rerun all of the autograder tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00a4341",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check_all()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "otter": {
   "OK_FORMAT": true,
   "assignment_name": "hw08_fa24",
   "tests": {
    "task_01": {
     "name": "task_01",
     "points": 3,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> 0 <= num_females <= 500\nTrue",
         "failure_message": "‚ùå num_females should be a value betwen 0 and 500.",
         "hidden": false,
         "locked": false,
         "points": 1,
         "success_message": "‚úÖ num_females is a value betwen 0 and 500."
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "task_02": {
     "name": "task_02",
     "points": 3,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> import numpy as np\n>>> type(avg_male_vs_female) in set([bool, np.bool_])\nTrue",
         "failure_message": "‚ùå avg_male_vs_female should be a bool.",
         "hidden": false,
         "locked": false,
         "points": 1,
         "success_message": "‚úÖ avg_male_vs_female is a bool."
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "task_03": {
     "name": "task_03",
     "points": 3,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> type(null_statement_number) == int\nTrue",
         "failure_message": "‚ùå null_statement_number should be an int.",
         "hidden": false,
         "locked": false,
         "points": 0.2,
         "success_message": "‚úÖ null_statement_number is an int."
        },
        {
         "code": ">>> type(alternative_statement_number) == int\nTrue",
         "failure_message": "‚ùå alternative_statement_number should be an int.",
         "hidden": false,
         "locked": false,
         "points": 0.2,
         "success_message": "‚úÖ alternative_statement_number is an int."
        },
        {
         "code": ">>> any((null_statement_number == x for x in np.arange(1, 7)))\nTrue",
         "failure_message": "‚ùå null_statement_number should be a number between 1 and 6.",
         "hidden": false,
         "locked": false,
         "points": 0.2,
         "success_message": "‚úÖ null_statement_number is a number between 1 and 6."
        },
        {
         "code": ">>> any((alternative_statement_number == x for x in np.arange(1, 7)))\nTrue",
         "failure_message": "‚ùå alternative_statement_number should be a number between 1 and 6.",
         "hidden": false,
         "locked": false,
         "points": 0.2,
         "success_message": "‚úÖ alternative_statement_number is a number between 1 and 6."
        },
        {
         "code": ">>> null_statement_number != alternative_statement_number\nTrue",
         "failure_message": "‚ùå null_statement_number should not the same as alternative_statement_number.",
         "hidden": false,
         "locked": false,
         "points": 0.2,
         "success_message": "‚úÖ null_statement_number is not the same as alternative_statement_number."
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "task_05": {
     "name": "task_05",
     "points": 3,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> type(correct_test_stat) == int\nTrue",
         "failure_message": "‚ùå correct_test_stat should be an int.",
         "hidden": false,
         "locked": false,
         "points": 0.5,
         "success_message": "‚úÖ correct_test_stat is an int."
        },
        {
         "code": ">>> any((correct_test_stat == x for x in np.arange(1, 3)))\nTrue",
         "failure_message": "‚ùå correct_test_stat should be either 1 or 2.",
         "hidden": false,
         "locked": false,
         "points": 0.5,
         "success_message": "‚úÖ correct_test_stat is either 1 or 2."
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "task_06": {
     "name": "task_06",
     "points": 3,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> type(observed_statistic_ab) == float\nTrue",
         "failure_message": "‚ùå observed_statistic_ab should be a float.",
         "hidden": false,
         "locked": false,
         "points": 0.5,
         "success_message": "‚úÖ observed_statistic_ab is a float."
        },
        {
         "code": ">>> observed_statistic_ab >= 0\nTrue",
         "failure_message": "‚ùå observed_statistic_ab should be 0 or larger.",
         "hidden": false,
         "locked": false,
         "points": 0.5,
         "success_message": "‚úÖ observed_statistic_ab is 0 or larger."
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "task_07": {
     "name": "task_07",
     "points": 3,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> type(original_with_shuffled_labels) == Table\nTrue",
         "failure_message": "‚ùå original_with_shuffled_labels should be a Table.",
         "hidden": false,
         "locked": false,
         "points": 0.25,
         "success_message": "‚úÖ original_with_shuffled_labels is a Table."
        },
        {
         "code": ">>> set(original_with_shuffled_labels.labels) == {'Gender', 'Age', 'Shuffled Label'}\nTrue",
         "failure_message": "‚ùå The labels for original_with_shuffled_labels are not correct.",
         "hidden": false,
         "locked": false,
         "points": 0.25,
         "success_message": "‚úÖ The labels for original_with_shuffled_labels are correct."
        },
        {
         "code": ">>> original_with_shuffled_labels.num_rows == 500\nTrue",
         "failure_message": "‚ùå original_with_shuffled_labels doesn't have the correct number of rows.",
         "hidden": false,
         "locked": false,
         "points": 0.5,
         "success_message": "‚úÖ original_with_shuffled_labels has the correct number of rows."
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "task_08": {
     "name": "task_08",
     "points": 3,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> type(correct_q8) == int\nTrue",
         "failure_message": "‚ùå correct_q8 should be an int.",
         "hidden": false,
         "locked": false,
         "points": 0.5,
         "success_message": "‚úÖ correct_q8 is an int."
        },
        {
         "code": ">>> any((correct_q8 == x for x in np.arange(1, 4)))\nTrue",
         "failure_message": "‚ùå correct_q8 should be a number between 1 and 3.",
         "hidden": false,
         "locked": false,
         "points": 0.5,
         "success_message": "‚úÖ correct_q8 is a number between 1 and 3."
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "task_09": {
     "name": "task_09",
     "points": 3,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> reps = 100\n>>> num_within_5 = sum((-5 < simulate_one_statistic() < 5 for _ in range(reps)))\n>>> num_within_5 / reps >= 0.95\nTrue",
         "failure_message": "‚ùå simulate_one_statistic() should return values between -5 and 5.",
         "hidden": false,
         "locked": false,
         "points": 1,
         "success_message": "‚úÖ simulate_one_statistic() returns values between -5 and 5."
        },
        {
         "code": ">>> np.random.seed(2024)\n>>> np.isclose(simulate_one_statistic(), 0.5769230769230802)\nTrue",
         "failure_message": "‚ùå simulate_one_statistic doesn't seem to be working correctly.",
         "hidden": false,
         "locked": false,
         "points": 2,
         "success_message": "‚úÖ simulate_one_statistic seems to be working correctly"
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "task_10": {
     "name": "task_10",
     "points": 3,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> len(simulated_statistics_ab) == 4000\nTrue",
         "failure_message": "‚ùå simulated_statistics_ab should have 4,000 elements.",
         "hidden": false,
         "locked": false,
         "points": 1,
         "success_message": "‚úÖ simulated_statistics_ab has 4,000 elements."
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "task_11": {
     "name": "task_11",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> import numpy as np\n>>> type(p_val) in set([float, np.float32, np.float64])\nTrue",
         "failure_message": "‚ùå p_val should be a float.",
         "hidden": false,
         "locked": false,
         "points": 0.5,
         "success_message": "‚úÖ p_val is a float."
        },
        {
         "code": ">>> 0 <= p_val <= 1\nTrue",
         "failure_message": "‚ùå p_val should be a number between 0 and 1.",
         "hidden": false,
         "locked": false,
         "points": 0.5,
         "success_message": "‚úÖ p_val is a number between 0 and 1."
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
